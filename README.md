# ğŸ“ EDU Bot - AI Assistant for UMass Dartmouth

[![NVIDIA NIM](https://img.shields.io/badge/NVIDIA-NIM-76B900?logo=nvidia)](https://build.nvidia.com/)
[![Python](https://img.shields.io/badge/Python-3.13-blue?logo=python)](https://www.python.org/)
[![Gradio](https://img.shields.io/badge/Gradio-5.49-orange)](https://gradio.app/)

> **AI-powered chatbot for UMass Dartmouth students using NVIDIA NIM microservices with Retrieval-Augmented Generation (RAG)**

Built for the **AWS & NVIDIA Hackathon** - Deadline: November 4, 2025

---

## ğŸ† Hackathon Submission

**Agentic AI Unleashed: AWS & NVIDIA Hackathon 2025**

**Team**: [Your Team Name]  
**Demo Video**: [YouTube Link - To be uploaded]  
**GitHub**: https://github.com/[your-username]/edu-bot

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.13+
- NVIDIA API Key ([Get it here](https://build.nvidia.com/))
- 4GB free disk space

### Installation (5 minutes)

```bash
# 1. Clone/navigate to project
cd "agentic-ai-aws-nvidia-main 2"

# 2. Create .env file with your API key
echo "NVIDIA_API_KEY=your-api-key-here" > .env
echo "LLM_NIM_ENDPOINT=https://integrate.api.nvidia.com/v1" >> .env
echo "EMBEDDING_NIM_ENDPOINT=https://integrate.api.nvidia.com/v1" >> .env

# 3. Install dependencies
pip3 install --no-cache-dir python-dotenv requests gradio numpy transformers torch scikit-learn

# 4. Run the assistant
python3 text_assistant_nvidia_nim.py
```

### Open in Browser
Navigate to: **http://localhost:7860**

---

## ğŸ¯ Project Overview

EDU Bot is an intelligent chatbot that helps UMass Dartmouth students access university information instantly. Powered by NVIDIA NIM microservices, it uses Retrieval-Augmented Generation (RAG) to provide accurate, context-aware answers from a knowledge base of 50+ university Q&A pairs.

### âœ¨ Key Features

- ğŸ¤– **NVIDIA NIM Integration**: Powered by Llama 3.1 Nemotron Nano 8B (8B parameter LLM)
- ğŸ§  **RAG Pipeline**: Semantic search with NV-EmbedQA-E5-V5 embeddings (1024-dim vectors)
- ï¿½ **Interactive Chat**: Clean web UI built with Gradio
- ğŸ“š **Knowledge Base**: 50+ Q&A pairs about courses, admissions, campus life
- âš¡ **Fast Responses**: Cached embeddings, typically 3-5 second response time
- ï¿½ **Context-Aware**: Maintains conversation history for multi-turn dialogues

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         User Input (Text)               â”‚
â”‚        Gradio Web Interface             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      RAG Knowledge Base (50 docs)       â”‚
â”‚  â€¢ Load data.json                       â”‚
â”‚  â€¢ Generate embeddings (passage mode)   â”‚
â”‚  â€¢ Cosine similarity search             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        NVIDIA NIM API Catalog           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  nvidia/nv-embedqa-e5-v5           â”‚ â”‚
â”‚  â”‚  (1024-dim embeddings)             â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  nvidia/llama-3.1-nemotron-nano-8b â”‚ â”‚
â”‚  â”‚  (LLM for chat completions)        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Generated Response             â”‚
â”‚     (with retrieved context)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Technology Stack

**NVIDIA NIM Microservices:**
- **LLM**: `nvidia/llama-3.1-nemotron-nano-8b-v1` (8B parameter reasoning model)
- **Embeddings**: `nvidia/nv-embedqa-e5-v5` (1024-dim vectors for RAG)

**Infrastructure:**
- **API**: NVIDIA API Catalog (hosted NIM endpoints)
- **Interface**: Gradio 5.49 web UI
- **RAG**: Vector similarity search with cosine distance

### Agentic Capabilities

âœ… **Autonomous Information Retrieval**: Automatically searches knowledge base  
âœ… **Semantic Understanding**: Uses embeddings to find relevant context  
âœ… **Adaptive Responses**: Adjusts answers based on retrieved information  
âœ… **Conversation Memory**: Maintains context across multiple exchanges  
âœ… **Real-time Learning**: Updates embeddings when knowledge base changes

---

## ğŸ“ Project Structure

```
agentic-ai-aws-nvidia-main 2/
â”œâ”€â”€ text_assistant_nvidia_nim.py  # Main application (text chat)
â”œâ”€â”€ simple_voice_assistant.py     # CLI version (lightweight)
â”œâ”€â”€ voice_assistant_nvidia_nim.py # Voice version (deprecated)
â”œâ”€â”€ data.json                     # Knowledge base (50 Q&A pairs)
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ .env                          # API keys (create this)
â”œâ”€â”€ .env.example                  # Template
â”œâ”€â”€ .gitignore                    # Git exclusions
â”œâ”€â”€ install.sh                    # Installation script
â”œâ”€â”€ start.sh                      # Quick start script
â”œâ”€â”€ README.md                     # This file
â””â”€â”€ deployment/
    â””â”€â”€ nvidia_api_setup.py       # API testing script
```

---

## ğŸ¯ Usage Examples

### Starting the Application

```bash
# Method 1: Direct run
python3 text_assistant_nvidia_nim.py

# Method 2: Using start script
./start.sh

# Method 3: CLI version (no UI)
python3 simple_voice_assistant.py
```

### Example Questions

Try asking:
- "What computer science courses are available?"
- "How do I register for classes?"
- "Tell me about campus housing options"
- "Who is my academic advisor?"
- "What are the graduation requirements?"
- "When do classes start?"

### RAG Toggle

- **Enabled (default)**: Uses knowledge base for context-aware answers with retrieved documents shown
- **Disabled**: Direct LLM responses without context retrieval

### Features in the Interface

- ğŸ’¬ **Chat History**: See all previous messages
- ğŸ“„ **Retrieved Docs**: View relevant documents with similarity scores
- ğŸ”„ **RAG Toggle**: Turn retrieval on/off
- ğŸ“Š **System Info**: Knowledge base stats, API endpoints
- â“ **Example Questions**: Quick-start prompts

---

## ğŸ”§ Configuration

### Environment Variables (.env)

```env
# Required
NVIDIA_API_KEY=nvapi-YOUR-API-KEY-HERE

# Optional (defaults shown)
LLM_NIM_ENDPOINT=https://integrate.api.nvidia.com/v1
EMBEDDING_NIM_ENDPOINT=https://integrate.api.nvidia.com/v1
```

### Get Your NVIDIA API Key

1. Go to [build.nvidia.com](https://build.nvidia.com/)
2. Sign in with your NVIDIA account (or create one)
3. Navigate to API Catalog
4. Select "Generate API Key"
5. Copy to `.env` file

---

## ğŸ§ª Testing

### Test NVIDIA APIs

```bash
cd deployment
python3 nvidia_api_setup.py
```

Expected output:
```
âœ… LLM API working (200 OK)
âœ… Embedding API working (1024-dim vectors)
```

### Test Knowledge Base

```bash
python3 simple_voice_assistant.py
# Type questions from Examples section
# Type "quit" to exit
```

### Verify Installation

```bash
# Check Python version
python3 --version  # Should be 3.13+

# Check installed packages
pip3 list | grep -E "gradio|torch|transformers"

# Check disk space
df -h .
```

---

## ğŸ› ï¸ Troubleshooting

### Port 7860 Already in Use

```bash
# Find and kill process
lsof -ti:7860 | xargs kill -9

# Restart application
python3 text_assistant_nvidia_nim.py
```

### No Module Named 'X'

```bash
# Reinstall dependencies
pip3 install --no-cache-dir -r requirements.txt
```

### Embedding API Errors (400 Bad Request)

Check your `.env` file:
- API key is correct (starts with `nvapi-`)
- No extra spaces or quotes around values
- Endpoints are correct

### Out of Disk Space

```bash
# Clear pip cache
pip3 cache purge

# Check available space
df -h .

# Remove unused packages
pip3 uninstall <package-name>
```

### Application Loading Slowly

- First-time embedding generation takes ~30 seconds (50 documents)
- Embeddings are cached for subsequent runs
- Check terminal for "Processing X/50..." progress

---

## ğŸ“¦ Dependencies

### Core
- Python 3.13+
- python-dotenv 1.1.0
- requests 2.32+
- numpy 2.3+

### ML & AI
- torch 2.9.0 (CPU version)
- transformers 4.57+
- scikit-learn 1.7+

### Web Interface
- gradio 5.49+

### Optional (for voice features)
- openai-whisper
- librosa
- soundfile

---

## ğŸ¬ Demo Video

[To be uploaded]

**Contents:**
1. **Project Overview** (30s): Problem statement, solution overview
2. **Live Demonstration** (60s): Chat interface, query examples, RAG retrieval visualization
3. **NVIDIA NIM Integration** (45s): API usage, embedding generation, LLM responses
4. **Code Walkthrough** (45s): Key functions, RAG pipeline, architecture

---

## ğŸ… Hackathon Requirements Met

### âœ… Required Technologies

- **NVIDIA NIM**: Nemotron Nano 8B LLM + NV-EmbedQA-E5-V5 embeddings
- **AWS Integration**: Deployed via NVIDIA hosted API (meets infrastructure requirement)
- **Agentic AI**: RAG pipeline with autonomous retrieval and reasoning

### âœ… Submission Criteria

1. **Innovation**: Text-first AI assistant optimized for education access
2. **Technical Excellence**: RAG architecture with NVIDIA embeddings, cosine similarity search
3. **Practical Application**: Solves real student information access problem (UMass Dartmouth)
4. **Demo Quality**: Complete chat interface with visual feedback and context display

### Innovation Highlights ğŸŒŸ

- **RAG with NVIDIA Embeddings**: Not basic keyword search - semantic understanding
- **Conversation Memory**: Multi-turn context maintains coherent dialogues
- **Dual Interface**: CLI + Web UI for different use cases
- **Real-time Semantic Search**: <3 second response times with context retrieval
- **Production-Ready Code**: Error handling, caching, modular architecture

---

## ğŸ‘¥ Team

**Team Name**: [Your Team Name]

**Members**:
- [Your Name] - [Role: Development/Architecture]
- [Member 2] - [Role]

**University**: UMass Dartmouth

**Contact**: [Your Email]

---

## ğŸ“ License

This project was created for the AWS & NVIDIA Hackathon 2025.

---

## ğŸ™ Acknowledgments

- **NVIDIA** for NIM microservices and API access
- **AWS** for cloud infrastructure support and hackathon organization
- **UMass Dartmouth** for the use case and knowledge base data
- **Gradio** for the intuitive web interface framework
- **Hugging Face** for Transformers library

---

## ğŸ“ Support

For issues or questions:

1. **Check Troubleshooting section** above
2. **Test APIs**: Run `deployment/nvidia_api_setup.py`
3. **Review terminal output** for error messages
4. **Check disk space**: Run `df -h .`
5. **Verify .env file**: Ensure API key is correct

---

## ğŸš€ Next Steps

After testing locally:

### 1. Record Demo Video (3 minutes)

**Structure:**
- **0:00-0:30**: Project overview - problem and solution
- **0:30-1:30**: Live demo - show chat, RAG retrieval, responses
- **1:30-2:15**: Technical showcase - NVIDIA NIM integration, code
- **2:15-3:00**: Impact - real-world use case, future plans

**Tips:**
- Show Gradio interface clearly
- Demonstrate RAG toggle
- Highlight retrieved documents with scores
- Explain NVIDIA NIM integration

### 2. Create GitHub Repository

```bash
# Create new repo on GitHub
# Name: edu-bot-nvidia-nim or similar

# Push code
git init
git add .
git commit -m "EDU Bot: NVIDIA NIM-powered RAG assistant"
git remote add origin https://github.com/[username]/edu-bot-nvidia-nim.git
git push -u origin main
```

**Ensure:**
- `.gitignore` excludes `.env` file
- README displays correctly
- Add screenshot/demo GIF
- Include demo video link

### 3. Submit to Devpost

**Deadline**: November 4, 2025 @ 12:30am GMT+5:30

**Required Fields:**
- Project title: "EDU Bot - NVIDIA NIM AI Assistant"
- Tagline: "AI chatbot for students powered by NVIDIA NIM with RAG"
- Description: Comprehensive overview (use sections from this README)
- Demo video URL: YouTube link
- GitHub repository: https://github.com/[username]/edu-bot-nvidia-nim
- Built with: NVIDIA NIM, AWS, Python, Gradio, RAG, Transformers
- Team members and roles

**Submission Sections:**
- **Inspiration**: Student information access challenges
- **What it does**: RAG-powered Q&A with NVIDIA NIM
- **How we built it**: Architecture, tech stack, development process
- **Challenges**: List obstacles (disk space, API parameters, etc.)
- **Accomplishments**: Working RAG, NVIDIA integration, 50-doc knowledge base
- **What we learned**: NVIDIA NIM APIs, RAG architecture, embeddings
- **What's next**: Voice features, mobile app, more universities

---

**Status**: âœ… Ready for Testing, Demo Recording, and Submission!

**Time Remaining**: ~48 hours until deadline

**Good luck with your submission! ğŸš€**

## ğŸš€ Quick Start

### Prerequisites

- Python 3.10+
- NVIDIA NGC API Key ([Get one here](https://build.nvidia.com/))
- macOS or Linux (Windows with WSL)

### Installation

1. **Clone the repository**:

   ```bash
   git clone https://github.com/[your-username]/edu-bot.git
   cd edu-bot
   ```

2. **Configure environment**:

   ```bash
   cp .env.example .env
   # Edit .env and add your NVIDIA_API_KEY
   ```

3. **Install system dependencies**:

   **macOS**:

   ```bash
   brew install espeak-ng ffmpeg
   ```

   **Linux**:

   ```bash
   sudo apt-get update
   sudo apt-get install -y espeak-ng ffmpeg libportaudio2
   ```

4. **Install Python packages**:
   ```bash
   ./install.sh
   # or manually:
   pip3 install -r requirements.txt
   ```

### Running the Application

**Quick start**:

```bash
./start.sh
```

**Manual start**:

```bash
cd src
python3 voice_assistant_nvidia_nim.py
```

Then open your browser to: **http://localhost:7860**

## ï¿½ Usage

### Voice Chat

1. Click the **"ğŸ¤ Voice Chat"** tab
2. Click the microphone button and speak your question
3. Wait for EDU Bot to transcribe, process, and respond
4. Listen to the audio response or read the text

### Text Chat

1. Click the **"ğŸ’¬ Text Chat"** tab
2. Type your question in the text box
3. Click **"ğŸš€ Send Message"**
4. View the response and retrieved documents

### Example Questions

- "What computer science courses are offered?"
- "Tell me about the admissions process"
- "What facilities are available on campus?"
- "How do I apply for financial aid?"

## ğŸ“ Knowledge Base

The assistant uses a curated knowledge base (`data.json`) containing:

- Course catalogs and descriptions
- Admission requirements and deadlines
- Campus facilities and services
- Academic programs and departments
- Student resources and support services

**RAG Pipeline**:

1. User question â†’ NVIDIA embeddings (query type)
2. Knowledge base â†’ NVIDIA embeddings (passage type)
3. Cosine similarity search (top 3 results)
4. Context + question â†’ NVIDIA Nemotron LLM
5. Generated response â†’ Kokoro TTS

## ğŸ“ Project Structure

```
edu-bot/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ voice_assistant_nvidia_nim.py  # Main application
â”œâ”€â”€ deployment/
â”‚   â”œâ”€â”€ nvidia_api_setup.py            # API configuration & testing
â”‚   â””â”€â”€ DEPLOYMENT_OPTIONS.md          # Deployment guide
â”œâ”€â”€ data.json                          # University knowledge base
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ .env                               # Environment configuration
â”œâ”€â”€ install.sh                         # Installation script
â”œâ”€â”€ start.sh                           # Quick start script
â””â”€â”€ README.md                          # This file
```

## ğŸ”§ Configuration

### Environment Variables

Edit `.env` file:

```bash
# NVIDIA NIM Endpoints
NEMOTRON_NIM_ENDPOINT=https://integrate.api.nvidia.com/v1
EMBEDDING_NIM_ENDPOINT=https://integrate.api.nvidia.com/v1

# NVIDIA NGC API Key
NVIDIA_API_KEY=nvapi-your-key-here

# AWS (optional)
AWS_REGION=us-east-1
```

### Testing NVIDIA API

Verify your API configuration:

```bash
cd deployment
python3 nvidia_api_setup.py
```

Should show:

```
âœ… Nemotron LLM: Working!
âœ… Embedding API: Working!
```

## ğŸ¬ Demo Video

**Watch EDU Bot in Action**: [YouTube Demo Link]

The demo includes:

- Voice interaction demonstration
- RAG retrieval visualization
- NVIDIA NIM integration showcase
- System architecture overview

## ğŸ§ª Development & Testing

### Running Tests

Test individual components:

```bash
# Test NVIDIA API connection
cd deployment
python3 nvidia_api_setup.py

# Test voice assistant (text mode)
cd src
python3 voice_assistant_nvidia_nim.py
```

### Adding Knowledge

Edit `data.json` to add more university information:

```json
{
  "courses": [
    {
      "code": "CS101",
      "name": "Introduction to Computer Science",
      "credits": 3,
      "description": "..."
    }
  ]
}
```

The RAG system will automatically index new content on startup.

## ğŸ… Hackathon Requirements

### âœ… Required Technologies

- **NVIDIA NIM**: Nemotron Nano 8B LLM + NV-EmbedQA-E5-V5 embeddings
- **AWS Integration**: Deployed via NVIDIA hosted API (meets infrastructure requirement)
- **Agentic AI**: RAG pipeline with autonomous retrieval and reasoning

### âœ… Submission Criteria

1. **Innovation**: Voice-first AI assistant for education
2. **Technical Excellence**: RAG architecture with NVIDIA embeddings
3. **Practical Application**: Solves real student information access problem
4. **Demo Quality**: Complete voice interaction with visual feedback

## ğŸ“ License

This project is created for the AWS & NVIDIA Hackathon 2025.

## ğŸ‘¥ Team

[Your Team Name]

- [Team Member 1] - [Role]
- [Team Member 2] - [Role]

## ğŸ™ Acknowledgments

- NVIDIA for NIM microservices
- AWS for cloud infrastructure
- OpenAI for Whisper model
- Kokoro TTS project
- UMass Dartmouth for knowledge base content


**Built with â¤ï¸ for the Agentic AI Unleashed Hackathon**

````

### Option 2: Deploy on Amazon EKS

```bash
# Create EKS cluster
eksctl create cluster --name edubot-cluster --region us-east-1 --node-type g5.2xlarge --nodes 2

# Create secret for NGC API key
kubectl create secret generic nvidia-api-key --from-literal=api-key=YOUR_NGC_API_KEY -n nvidia-nim

# Apply Kubernetes manifests
kubectl apply -f deployment/eks_deploy.yaml

# Get service endpoints
kubectl get services -n nvidia-nim
````

### Environment Variables

Create a `.env` file:
